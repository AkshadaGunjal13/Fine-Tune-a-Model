{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyO1ump1GcK+BhV8WdzlOaEt"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# Step 1: Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Step 2: Install Required Libraries\n","!pip install tensorflow opencv-python\n","\n","# Step 3: Import Libraries\n","import os\n","import cv2\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.applications import ResNet50\n","from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelBinarizer\n","\n","# Step 4: Define Constants\n","IMG_SIZE = 224\n","BATCH_SIZE = 32\n","EPOCHS = 20\n","DATASET_PATH = \"/content/drive/MyDrive/ColabNotebooks/UTKFace/\"\n","\n","# Step 5: Verify Dataset Path\n","if not os.path.exists(DATASET_PATH):\n","    raise FileNotFoundError(f\"Dataset folder not found at {DATASET_PATH}. Please check the path.\")\n","\n","# Step 6: Function to Group Ages into Bins\n","def age_to_group(age):\n","    if age <= 10:\n","        return 0\n","    elif 11 <= age <= 20:\n","        return 1\n","    elif 21 <= age <= 30:\n","        return 2\n","    elif 31 <= age <= 40:\n","        return 3\n","    elif 41 <= age <= 50:\n","        return 4\n","    elif 51 <= age <= 60:\n","        return 5\n","    else:\n","        return 6\n","\n","# Step 7: Get All Image Paths and Labels\n","image_paths = [os.path.join(DATASET_PATH, img) for img in os.listdir(DATASET_PATH) if img.endswith(\".jpg\")]\n","labels = [age_to_group(int(img.split(\"_\")[0])) for img in os.listdir(DATASET_PATH) if img.endswith(\".jpg\")]\n","\n","# Step 8: Convert Labels to One-Hot Encoding\n","label_binarizer = LabelBinarizer()\n","labels = label_binarizer.fit_transform(labels)\n","\n","# Step 9: Split into Training & Validation Sets\n","train_paths, val_paths, train_labels, val_labels = train_test_split(image_paths, labels, test_size=0.15, random_state=42)\n","\n","# Step 10: Custom Data Generator\n","class UTKFaceDataGenerator(tf.keras.utils.Sequence):\n","    def __init__(self, image_paths, labels, batch_size=BATCH_SIZE, img_size=(IMG_SIZE, IMG_SIZE), augment=False):\n","        self.image_paths = image_paths\n","        self.labels = labels\n","        self.batch_size = batch_size\n","        self.img_size = img_size\n","        self.augment = augment\n","\n","    def __len__(self):\n","        return int(np.floor(len(self.image_paths) / self.batch_size))\n","\n","    def __getitem__(self, index):\n","        batch_paths = self.image_paths[index * self.batch_size:(index + 1) * self.batch_size]\n","        batch_labels = self.labels[index * self.batch_size:(index + 1) * self.batch_size]\n","\n","        images = []\n","        for img_path in batch_paths:\n","            img = cv2.imread(img_path)\n","            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","            img = cv2.resize(img, self.img_size)\n","            img = img / 255.0\n","\n","            if self.augment:\n","                if np.random.rand() > 0.5:\n","                    img = cv2.flip(img, 1)\n","                img = tf.keras.preprocessing.image.random_rotation(img, 30)\n","                img = tf.keras.preprocessing.image.random_shift(img, 0.2, 0.2)\n","\n","            images.append(img)\n","\n","        return np.array(images), np.array(batch_labels)\n","\n","# Step 11: Create Data Generators\n","train_generator = UTKFaceDataGenerator(train_paths, train_labels, augment=True)\n","val_generator = UTKFaceDataGenerator(val_paths, val_labels)\n","\n","# Step 12: Load Pre-Trained ResNet50 Model\n","base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n","\n","# Step 13: Freeze Base Model Layers\n","for layer in base_model.layers:\n","    layer.trainable = False\n","\n","# Step 14: Add Custom Layers\n","x = base_model.output\n","x = GlobalAveragePooling2D()(x)\n","x = Dense(1024, activation='relu')(x)\n","x = Dropout(0.5)(x)\n","predictions = Dense(len(label_binarizer.classes_), activation='softmax')(x)\n","\n","# Step 15: Create Final Model\n","model = Model(inputs=base_model.input, outputs=predictions)\n","\n","# Step 16: Compile Model\n","model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Step 17: Train Model\n","history = model.fit(train_generator, validation_data=val_generator, epochs=EPOCHS)\n","\n","# Step 18: Save Model\n","model.save(\"/content/drive/MyDrive/age_prediction_model.h5\")\n","\n","# Step 19: Evaluate Model\n","test_loss, test_accuracy = model.evaluate(val_generator)\n","print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"69vIyEnqSCvL","executionInfo":{"status":"ok","timestamp":1752071085113,"user_tz":-330,"elapsed":332492,"user":{"displayName":"Akshada Gunjal","userId":"17152451300241560849"}},"outputId":"d6dbc364-8081-4d35-c258-40c274653407"},"execution_count":2,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.73.1)\n","Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n","Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n","Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n","Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.14.0)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n","Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.6.15)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8.2)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n","Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n","\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 8s/step - accuracy: 0.8150 - loss: 0.7485 - val_accuracy: 0.9062 - val_loss: 0.3385\n","Epoch 2/20\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 7s/step - accuracy: 0.7961 - loss: 0.6348 - val_accuracy: 0.9062 - val_loss: 0.3196\n","Epoch 3/20\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 8s/step - accuracy: 0.7997 - loss: 0.6408 - val_accuracy: 0.9062 - val_loss: 0.3218\n","Epoch 4/20\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 7s/step - accuracy: 0.8620 - loss: 0.5118 - val_accuracy: 0.9062 - val_loss: 0.3471\n","Epoch 5/20\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 8s/step - accuracy: 0.7600 - loss: 0.6522 - val_accuracy: 0.9062 - val_loss: 0.3387\n","Epoch 6/20\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 7s/step - accuracy: 0.8445 - loss: 0.5846 - val_accuracy: 0.9062 - val_loss: 0.3633\n","Epoch 7/20\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 7s/step - accuracy: 0.8082 - loss: 0.6153 - val_accuracy: 0.9062 - val_loss: 0.3219\n","Epoch 8/20\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 7s/step - accuracy: 0.8443 - loss: 0.5720 - val_accuracy: 0.9062 - val_loss: 0.3365\n","Epoch 9/20\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 7s/step - accuracy: 0.8203 - loss: 0.5621 - val_accuracy: 0.9062 - val_loss: 0.3239\n","Epoch 10/20\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 8s/step - accuracy: 0.8218 - loss: 0.6277 - val_accuracy: 0.9062 - val_loss: 0.3236\n","Epoch 11/20\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 7s/step - accuracy: 0.8255 - loss: 0.5879 - val_accuracy: 0.9062 - val_loss: 0.3260\n","Epoch 12/20\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 8s/step - accuracy: 0.8327 - loss: 0.5541 - val_accuracy: 0.9062 - val_loss: 0.3210\n","Epoch 13/20\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 7s/step - accuracy: 0.8200 - loss: 0.5949 - val_accuracy: 0.9062 - val_loss: 0.3204\n","Epoch 14/20\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 7s/step - accuracy: 0.8371 - loss: 0.5709 - val_accuracy: 0.9062 - val_loss: 0.3414\n","Epoch 15/20\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 7s/step - accuracy: 0.8459 - loss: 0.5436 - val_accuracy: 0.9062 - val_loss: 0.3271\n","Epoch 16/20\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 7s/step - accuracy: 0.8291 - loss: 0.5811 - val_accuracy: 0.9062 - val_loss: 0.3286\n","Epoch 17/20\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 7s/step - accuracy: 0.8147 - loss: 0.5877 - val_accuracy: 0.9062 - val_loss: 0.3290\n","Epoch 18/20\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 8s/step - accuracy: 0.8366 - loss: 0.5811 - val_accuracy: 0.9062 - val_loss: 0.3299\n","Epoch 19/20\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 7s/step - accuracy: 0.8490 - loss: 0.5560 - val_accuracy: 0.9062 - val_loss: 0.3402\n","Epoch 20/20\n","\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 7s/step - accuracy: 0.8446 - loss: 0.5595 - val_accuracy: 0.9062 - val_loss: 0.3351\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5s/step - accuracy: 0.8958 - loss: 0.3534\n","Test Loss: 0.3350868225097656, Test Accuracy: 0.90625\n"]}]}]}